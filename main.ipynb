{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Using cached langchain_core-0.3.30-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (2.1)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.30-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Installing collected packages: orjson, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.14 langchain-core-0.3.30 langchain-text-splitters-0.3.5 langsmith-0.2.11 orjson-3.10.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.30)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.11)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.0 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.25.1 pydantic-settings-2.7.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CSVLoader for .csv files\n",
    "loader =TextLoader(r'C:\\Users\\Subham Gupta\\Desktop\\Work\\Research ChatBot\\blogs_nvidia_com__blog_nemo-guardrails-nim-microservices_.txt')\n",
    "data  = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Subham Gupta\\\\Desktop\\\\Work\\\\Research ChatBot\\\\blogs_nvidia_com__blog_nemo-guardrails-nim-microservices_.txt'}, page_content='Home\\n\\nAI\\n\\nData Center\\n\\nDriving\\n\\nGaming\\n\\nPro Graphics\\n\\nRobotics\\n\\nHealthcare\\n\\nStartups\\n\\nAI Podcast\\n\\nNVIDIA Life\\n\\nNVIDIA Releases NIM Microservices to Safeguard Applications for Agentic\\nAI\\nNVIDIA NeMo Guardrails includes new NVIDIA NIM microservices to enhance accuracy, security and control for enterprises\\nbuilding AI across industries.\\nJanuary 16, 2025 by Kari Briski\\n\\nu\\n\\nShare\\n\\nf\\nh\\nd\\n\\nReading Time: 5 mins\\n\\nAI agents are poised to transform productivity for the world’s billion knowledge workers with\\n“knowledge robots” that can accomplish a variety of tasks. To develop AI agents, enterprises need\\nto address critical concerns like trust, safety, security and compliance.\\nNew NVIDIA NIM microservices for AI guardrails — part of the NVIDIA NeMo Guardrails collection of\\nsoftware tools — are portable, optimized inference microservices that help companies improve the\\nsafety, precision and scalability of their generative AI applications.\\nCentral to the orchestration of the microservices is NeMo Guardrails, part of the NVIDIA NeMo\\nplatform for curating, customizing and guardrailing AI. NeMo Guardrails helps developers integrate\\nand manage AI guardrails in large language model (LLM) applications. Industry leaders Amdocs,\\nCerence AI and Lowe’s are among those using NeMo Guardrails to safeguard AI applications.\\nDevelopers can use the NIM microservices to build more secure, trustworthy AI agents that provide\\nsafe, appropriate responses within context-specific guidelines and are bolstered against jailbreak\\nattempts. Deployed in customer service across industries like automotive, finance, healthcare,\\nmanufacturing and retail, the agents can boost customer satisfaction and trust.\\n\\nAll NVIDIA News\\nHow This NVIDIA Kaggle\\nGrandmaster Merges\\nInnovation and Play\\n\\nOne of the new microservices, built for moderating content safety, was trained using the Aegis\\nContent Safety Dataset — one of the highest-quality, human-annotated data sources in its\\ncategory. Curated and owned by NVIDIA, the dataset is publicly available on Hugging Face and\\nincludes over 35,000 human-annotated data samples flagged for AI safety and jailbreak attempts\\nto bypass system restrictions.\\n\\nNVIDIA NeMo Guardrails Keeps AI Agents on Track\\n\\nFantastic Four-ce\\nAwakens: Season One of\\n‘Marvel Rivals’ Joins\\nGeForce NOW\\n\\nAI is rapidly boosting productivity for a broad range of business processes. In customer service, it’s\\nhelping resolve customer issues up to 40% faster. However, scaling AI for customer service and\\nother AI agents requires secure models that prevent harmful or inappropriate outputs and ensure\\nthe AI application behaves within defined parameters.\\n\\nHow AI Is Enhancing\\nSurgical Safety and\\nEducation\\n\\nNVIDIA has introduced three new NIM microservices for NeMo Guardrails that help AI agents\\noperate at scale while maintaining controlled behavior:\\nNVIDIA GTC 2025:\\nQuantum Day to\\nIlluminate the Future of\\nQuantum Computing\\n\\nContent safety NIM microservice that safeguards AI against generating biased or harmful\\noutputs, ensuring responses align with ethical standards.\\nTopic control NIM microservice that keeps conversations focused on approved topics, avoiding\\ndigression or inappropriate content.\\nJailbreak detection NIM microservice that adds protection against jailbreak attempts, helping\\nmaintain AI integrity in adversarial scenarios.\\n\\nHealthcare Leaders,\\nNVIDIA CEO Share AI\\nInnovation Across the\\nIndustry\\n\\nBy applying multiple lightweight, specialized models as guardrails, developers can cover gaps that\\nmay occur when only more general global policies and protections exist — as a one-size-fits-all\\napproach doesn’t properly secure and control complex agentic AI workflows.\\nSmall language models, like those in the NeMo Guardrails collection, offer lower latency and are\\ndesigned to run efficiently, even in resource-constrained or distributed environments. This makes\\nthem ideal for scaling AI applications in industries such as healthcare, automotive and\\nmanufacturing, in locations like hospitals or warehouses.\\n\\nIndustry Leaders and Partners Safeguard AI With NeMo Guardrails\\nNeMo Guardrails, available to the open-source community, helps developers orchestrate multiple AI\\nsoftware policies — called rails — to enhance LLM application security and control. It works with\\nNVIDIA NIM microservices to offer a robust framework for building AI systems that can be\\ndeployed at scale without compromising on safety or performance.\\nAmdocs, a leading global provider of software and services to communications and media\\ncompanies, is harnessing NeMo Guardrails to enhance AI-driven customer interactions by\\ndelivering safer, more accurate and contextually appropriate responses.\\n“Technologies like NeMo Guardrails are essential for safeguarding generative AI applications,\\nhelping make sure they operate securely and ethically,” said Anthony Goonetilleke, group president\\nof technology and head of strategy at Amdocs. “By integrating NVIDIA NeMo Guardrails into our\\namAIz platform, we are enhancing the platform’s ‘Trusted AI’ capabilities to deliver agentic\\nexperiences that are safe, reliable and scalable. This empowers service providers to deploy AI\\nsolutions safely and with confidence, setting new standards for AI innovation and operational\\nexcellence.”\\nCerence AI, a company specializing in AI solutions for the automotive industry, is using NVIDIA\\nNeMo Guardrails to help ensure its in-car assistants deliver contextually appropriate, safe\\ninteractions powered by its CaLLM family of large and small language models.\\n“Cerence AI relies on high-performing, secure solutions from NVIDIA to power our in-car assistant\\ntechnologies,” said Nils Schanz, executive vice president of product and technology at Cerence AI.\\n“Using NeMo Guardrails helps us deliver trusted, context-aware solutions to our automaker\\ncustomers and provide sensible, mindful and hallucination-free responses. In addition, NeMo\\nGuardrails is customizable for our automaker customers and helps us filter harmful or unpleasant\\nrequests, securing our CaLLM family of language models from unintended or inappropriate\\ncontent delivery to end users.”\\nLowe’s, a leading home improvement retailer, is leveraging generative AI to build on the deep\\nexpertise of its store associates. By providing enhanced access to comprehensive product\\nknowledge, these tools empower associates to answer customer questions, helping them find the\\nright products to complete their projects and setting a new standard for retail innovation and\\ncustomer satisfaction.\\n“We’re always looking for ways to help associates to above and beyond for our customers,” said\\nChandhu Nair, senior vice president of data, AI and innovation at Lowe’s. “With our recent\\ndeployments of NVIDIA NeMo Guardrails, we ensure AI-generated responses are safe, secure and\\nreliable, enforcing conversational boundaries to deliver only relevant and appropriate content.”\\nTo further accelerate AI safeguards adoption in AI application development and deployment in\\nretail, NVIDIA recently announced at the NRF show that its NVIDIA AI Blueprint for retail shopping\\nassistants incorporates NeMo Guardrails microservices for creating more reliable and controlled\\ncustomer interactions during digital shopping experiences.\\nConsulting leaders Taskus, Tech Mahindra and Wipro are also integrating NeMo Guardrails into\\ntheir solutions to provide their enterprise clients safer, more reliable and controlled generative AI\\napplications.\\nNeMo Guardrails is open and extensible, offering integration with a robust ecosystem of leading AI\\nsafety model and guardrail providers, as well as AI observability and development tools. It supports\\nintegration with ActiveFence’s ActiveScore, which filters harmful or inappropriate content in\\nconversational AI applications, and provides visibility, analytics and monitoring.\\nHive, which provides its AI-generated content detection models for images, video and audio\\ncontent as NIM microservices, can be easily integrated and orchestrated in AI applications using\\nNeMo Guardrails.\\nThe Fiddler AI Observability platform easily integrates with NeMo Guardrails to enhance AI guardrail\\nmonitoring capabilities. And Weights & Biases, an end-to-end AI developer platform, is expanding\\nthe capabilities of W&B Weave by adding integrations with NeMo Guardrails microservices. This\\nenhancement builds on Weights & Biases’ existing portfolio of NIM integrations for optimized AI\\ninferencing in production.\\n\\nNeMo Guardrails Offers Open-Source Tools for AI Safety Testing\\nDevelopers ready to test the effectiveness of applying safeguard models and other rails can use\\nNVIDIA Garak — an open-source toolkit for LLM and application vulnerability scanning developed\\nby the NVIDIA Research team.\\nWith Garak, developers can identify vulnerabilities in systems using LLMs by assessing them for\\nissues such as data leaks, prompt injections, code hallucination and jailbreak scenarios. By\\ngenerating test cases involving inappropriate or incorrect outputs, Garak helps developers detect\\nand address potential weaknesses in AI models to enhance their robustness and safety.\\n\\nAvailability\\nNVIDIA NeMo Guardrails microservices, as well as NeMo Guardrails for rail orchestration and the\\nNVIDIA Garak toolkit, are now available for developers and enterprises. Developers can get started\\nbuilding AI safeguards into AI agents for customer service using NeMo Guardrails with this tutorial.\\nSee notice regarding software product information.\\n\\nCategories: Generative AI\\nTags: Artificial Intelligence | Cybersecurity | NVIDIA Blueprints | NVIDIA NeMo | NVIDIA NIM\\n1\\nLogin\\n\\ue603\\n\\n0 Comments\\n\\nG\\n\\nStart the discussion…\\n\\nLOG IN WITH\\n\\nOR SIGN UP WITH DISQUS\\n\\n?\\n\\nName\\n\\n\\uf109\\n\\nShare\\n\\nBest\\n\\nNewest\\n\\nOldest\\n\\nBe the first to comment.\\n\\nSubscribe\\n\\nPrivacy\\n\\nDo Not Sell My Data\\n\\nUnveiling a New Era of Local AI With NVIDIA NIM Microservices and AI\\nBlueprints\\nNew NIM microservices and AI Blueprints unlock generative AI on RTX AI PCs and workstation — plus, more announcements\\nfrom CES recapped in this first installment of the RTX AI Garage series.\\nJanuary 8, 2025 by Jesse Clayton\\n\\nu\\n\\nShare\\n\\nf\\nh\\nd\\n\\nReading Time: 5 mins\\n\\nOver the past year, generative AI has transformed the way people live, work and play, enhancing\\neverything from writing and content creation to gaming, learning and productivity. PC enthusiasts\\nand developers are leading the charge in pushing the boundaries of this groundbreaking\\ntechnology.\\nCountless times, industry-defining technological breakthroughs have been invented in one place —\\na garage. This week marks the start of the RTX AI Garage series, which will offer routine content for\\ndevelopers and enthusiasts looking to learn more about NVIDIA NIM microservices and AI\\nBlueprints, and how to build AI agents, creative workflow, digital human, productivity apps and\\nmore on AI PCs. Welcome to the RTX AI Garage.\\nThis first installment spotlights announcements made earlier this week at CES, including new AI\\nfoundation models available on NVIDIA RTX AI PCs that take digital humans, content creation,\\nproductivity and development to the next level.\\n\\nAll NVIDIA News\\n\\nThese models — offered as NVIDIA NIM microservices — are powered by new GeForce RTX 50\\nSeries GPUs. Built on the NVIDIA Blackwell architecture, RTX 50 Series GPUs deliver up to 3,352\\ntrillion AI operations per second of performance, 32GB of VRAM and feature FP4 compute,\\ndoubling AI inference performance and enabling generative AI to run locally with a smaller memory\\nfootprint.\\n\\nHow This NVIDIA Kaggle\\nGrandmaster Merges\\nInnovation and Play\\n\\nNVIDIA also introduced NVIDIA AI Blueprints — ready-to-use, preconfigured workflows, built on NIM\\nmicroservices, for applications like digital humans and content creation.\\n\\nNVIDIA Releases NIM\\nMicroservices to\\nSafeguard Applications\\nfor Agentic AI\\n\\nNIM microservices and AI Blueprints empower enthusiasts and developers to build, iterate and\\ndeliver AI-powered experiences to the PC faster than ever. The result is a new wave of compelling,\\npractical capabilities for PC users.\\n\\nFantastic Four-ce\\nAwakens: Season One of\\n‘Marvel Rivals’ Joins\\nGeForce NOW\\n\\nFast-Track AI With NVIDIA NIM\\nThere are two key challenges to bringing AI advancements to PCs. First, the pace of AI research is\\nbreakneck, with new models appearing daily on platforms like Hugging Face, which now hosts over\\na million models. As a result, breakthroughs quickly become outdated.\\n\\nHow AI Is Enhancing\\nSurgical Safety and\\nEducation\\n\\nSecond, adapting these models for PC use is a complex, resource-intensive process. Optimizing\\nthem for PC hardware, integrating them with AI software and connecting them to applications\\nrequires significant engineering effort.\\nNVIDIA NIM helps address these challenges by offering prepackaged, state-of-the-art AI models\\noptimized for PCs. These NIM microservices span model domains, can be installed with a single\\nclick, feature application programming interfaces (APIs) for easy integration, and harness NVIDIA AI\\nsoftware and RTX GPUs for accelerated performance.\\n\\nNVIDIA GTC 2025:\\nQuantum Day to\\nIlluminate the Future of\\nQuantum Computing\\n\\nAt CES, NVIDIA announced a pipeline of NIM microservices for RTX AI PCs, supporting use cases\\nspanning large language models (LLMs), vision-language models, image generation, speech,\\nretrieval-augmented generation (RAG), PDF extraction and computer vision.\\nThe new Llama Nemotron family of open models provide high accuracy on a wide range of agentic\\ntasks. The Llama Nemotron Nano model, which will be offered as a NIM microservice for RTX AI PCs\\nand workstations, excels at agentic AI tasks like instruction following, function calling, chat, coding\\nand math.\\nSoon, developers will be able to quickly download and run these microservices on Windows 11 PCs\\nusing Windows Subsystem for Linux (WSL).\\n\\nIntroducing Project R2X | A Preview of a RTX-Powered Digital Human Interface\\n\\nTo demonstrate how enthusiasts and developers can use NIM to build AI agents and assistants,\\nNVIDIA previewed Project R2X, a vision-enabled PC avatar that can put information at a user’s\\nfingertips, assist with desktop apps and video conference calls, read and summarize documents,\\nand more. Sign up for Project R2X updates.\\nBy using NIM microservices, AI enthusiasts can skip the complexities of model curation,\\noptimization and backend integration and focus on creating and innovating with cutting-edge AI\\nmodels.\\n\\nWhat’s in an API?\\nAn API is the way in which an application communicates with a software library. An API defines a\\nset of “calls” that the application can make to the library and what the application can expect in\\nreturn. Traditional AI APIs require a lot of setup and configuration, making AI capabilities harder to\\nuse and hampering innovation.\\nNIM microservices expose easy-to-use, intuitive APIs that an application can simply send requests\\nto and get a response. In addition, they’re designed around the input and output media for\\ndifferent model types. For example, LLMs take text as input and produce text as output, image\\ngenerators convert text to image, speech recognizers turn speech to text and so on.\\nThe microservices are designed to integrate seamlessly with leading AI development and agent\\nframeworks such as AI Toolkit for VSCode, AnythingLLM, ComfyUI, Flowise AI, LangChain, Langflow\\nand LM Studio. Developers can easily download and deploy them from build.nvidia.com.\\nBy bringing these APIs to RTX, NVIDIA NIM will accelerate AI innovation on PCs.\\nEnthusiasts are expected to be able to experience a range of NIM microservices using an\\nupcoming release of the NVIDIA ChatRTX tech demo.\\n\\nA Blueprint for Innovation\\nBy using state-of-the-art models, prepackaged and optimized for PCs, developers and enthusiasts\\ncan quickly create AI-powered projects. Taking things a step further, they can combine multiple AI\\nmodels and other functionality to build complex applications like digital humans, podcast\\ngenerators and application assistants.\\nNVIDIA AI Blueprints, built on NIM microservices, are reference implementations for complex AI\\nworkflows. They help developers connect several components, including libraries, software\\ndevelopment kits and AI models, together in a single application.\\n\\nNVIDIA NIM Microservices for RTX AI PCs\\n\\nAI Blueprints include everything that a developer needs to build, run, customize and extend the\\nreference workflow, which includes the reference application and source code, sample data, and\\ndocumentation for customization and orchestration of the different components.\\nAt CES, NVIDIA announced two AI Blueprints for RTX: one for PDF to podcast, which lets users\\ngenerate a podcast from any PDF, and another for 3D-guided generative AI, which is based on\\nFLUX.1 [dev] and expected be offered as a NIM microservice, offers artists greater control over\\ntext-based image generation.\\nWith AI Blueprints, developers can quickly go from AI experimentation to AI development for\\ncutting-edge workflows on RTX PCs and workstations.\\n\\nBuilt for Generative AI\\nThe new GeForce RTX 50 Series GPUs are purpose-built to tackle complex generative AI challenges,\\nfeaturing fifth-generation Tensor Cores with FP4 support, faster G7 memory and an AImanagement processor for efficient multitasking between AI and creative workflows.\\nThe GeForce RTX 50 Series adds FP4 support to help bring better performance and more models\\nto PCs. FP4 is a lower quantization method, similar to file compression, that decreases model sizes.\\nCompared with FP16 — the default method that most models feature — FP4 uses less than half of\\nthe memory, and 50 Series GPUs provide over 2x performance compared with the previous\\ngeneration. This can be done with virtually no loss in quality with advanced quantization methods\\noffered by NVIDIA TensorRT Model Optimizer.\\nFor example, Black Forest Labs’ FLUX.1 [dev] model at FP16 requires over 23GB of VRAM, meaning\\nit can only be supported by the GeForce RTX 4090 and professional GPUs. With FP4, FLUX.1 [dev]\\nrequires less than 10GB, so it can run locally on more GeForce RTX GPUs.\\nWith a GeForce RTX 4090 with FP16, the FLUX.1 [dev] model can generate images in 15 seconds\\nwith 30 steps. With a GeForce RTX 5090 with FP4, images can be generated in just over five\\nseconds.\\n\\nGet Started With the New AI APIs for PCs\\nNVIDIA NIM microservices and AI Blueprints are expected to be available starting next month, with\\ninitial hardware support for GeForce RTX 50 Series, GeForce RTX 4090 and 4080, and NVIDIA RTX\\n6000 and 5000 professional GPUs. Additional GPUs will be supported in the future.\\nNIM-ready RTX AI PCs are expected to be available from Acer, ASUS, Dell, GIGABYTE, HP, Lenovo,\\nMSI, Razer and Samsung, and from local system builders Corsair, Falcon Northwest, LDLC,\\nMaingear, Mifcon, Origin PC, PCS and Scan.\\nGeForce RTX 50 Series GPUs and laptops deliver game-changing performance, power\\ntransformative AI experiences, and enable creators to complete workflows in record time. Rewatch\\nNVIDIA CEO Jensen Huang’s keynote to learn more about NVIDIA’s AI news unveiled at CES.\\nSee notice regarding software product information.\\n\\nCategories: Generative AI\\nTags: AI Decoded | Artificial Intelligence | GeForce | NVIDIA RTX\\nLoad Comments\\n\\nCorporate Information\\n\\nGet Involved\\n\\nNews & Events\\n\\nAbout NVIDIA\\n\\nForums\\n\\nNewsroom\\n\\nCorporate Overview\\n\\nCareers\\n\\nNVIDIA Blog\\n\\nTechnologies\\n\\nDeveloper Home\\n\\nNVIDIA Technical Blog\\n\\nNVIDIA Research\\n\\nJoin the Developer Program\\n\\nWebinars\\n\\nInvestors\\n\\nNVIDIA Partner Network\\n\\nStay Informed\\n\\nSocial Responsibility\\n\\nNVIDIA Inception\\n\\nEvents Calendar\\n\\nNVIDIA Foundation\\n\\nResources for Venture Capitalists\\n\\nNVIDIA GTC\\n\\nVenture Capital (NVentures)\\n\\nNVIDIA On-Demand\\n\\nTechnical Training\\nTraining for IT Professionals\\nProfessional Services for Data Science\\n\\nEXPLORE OUR REGIONAL BLOGS AND OTHER SOCIAL NETWORKS\\n\\ne\\nUSA - United States\\n\\nPrivacy Policy\\n\\nManage My Privacy\\n\\nContact\\nCopyright © 2025 NVIDIA Corporation\\n\\nLegal\\n\\nAccessibility\\n\\nProduct Security\\n\\n\\x0c')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Home\\n\\nAI\\n\\nData Center\\n\\nDriving\\n\\nGaming\\n\\nPro Graphics\\n\\nRobotics\\n\\nHealthcare\\n\\nStartups\\n\\nAI Podcast\\n\\nNVIDIA Life\\n\\nNVIDIA Releases NIM Microservices to Safeguard Applications for Agentic\\nAI\\nNVIDIA NeMo Guardrails includes new NVIDIA NIM microservices to enhance accuracy, security and control for enterprises\\nbuilding AI across industries.\\nJanuary 16, 2025 by Kari Briski\\n\\nu\\n\\nShare\\n\\nf\\nh\\nd\\n\\nReading Time: 5 mins\\n\\nAI agents are poised to transform productivity for the world’s billion knowledge workers with\\n“knowledge robots” that can accomplish a variety of tasks. To develop AI agents, enterprises need\\nto address critical concerns like trust, safety, security and compliance.\\nNew NVIDIA NIM microservices for AI guardrails — part of the NVIDIA NeMo Guardrails collection of\\nsoftware tools — are portable, optimized inference microservices that help companies improve the\\nsafety, precision and scalability of their generative AI applications.\\nCentral to the orchestration of the microservices is NeMo Guardrails, part of the NVIDIA NeMo\\nplatform for curating, customizing and guardrailing AI. NeMo Guardrails helps developers integrate\\nand manage AI guardrails in large language model (LLM) applications. Industry leaders Amdocs,\\nCerence AI and Lowe’s are among those using NeMo Guardrails to safeguard AI applications.\\nDevelopers can use the NIM microservices to build more secure, trustworthy AI agents that provide\\nsafe, appropriate responses within context-specific guidelines and are bolstered against jailbreak\\nattempts. Deployed in customer service across industries like automotive, finance, healthcare,\\nmanufacturing and retail, the agents can boost customer satisfaction and trust.\\n\\nAll NVIDIA News\\nHow This NVIDIA Kaggle\\nGrandmaster Merges\\nInnovation and Play\\n\\nOne of the new microservices, built for moderating content safety, was trained using the Aegis\\nContent Safety Dataset — one of the highest-quality, human-annotated data sources in its\\ncategory. Curated and owned by NVIDIA, the dataset is publicly available on Hugging Face and\\nincludes over 35,000 human-annotated data samples flagged for AI safety and jailbreak attempts\\nto bypass system restrictions.\\n\\nNVIDIA NeMo Guardrails Keeps AI Agents on Track\\n\\nFantastic Four-ce\\nAwakens: Season One of\\n‘Marvel Rivals’ Joins\\nGeForce NOW\\n\\nAI is rapidly boosting productivity for a broad range of business processes. In customer service, it’s\\nhelping resolve customer issues up to 40% faster. However, scaling AI for customer service and\\nother AI agents requires secure models that prevent harmful or inappropriate outputs and ensure\\nthe AI application behaves within defined parameters.\\n\\nHow AI Is Enhancing\\nSurgical Safety and\\nEducation\\n\\nNVIDIA has introduced three new NIM microservices for NeMo Guardrails that help AI agents\\noperate at scale while maintaining controlled behavior:\\nNVIDIA GTC 2025:\\nQuantum Day to\\nIlluminate the Future of\\nQuantum Computing\\n\\nContent safety NIM microservice that safeguards AI against generating biased or harmful\\noutputs, ensuring responses align with ethical standards.\\nTopic control NIM microservice that keeps conversations focused on approved topics, avoiding\\ndigression or inappropriate content.\\nJailbreak detection NIM microservice that adds protection against jailbreak attempts, helping\\nmaintain AI integrity in adversarial scenarios.\\n\\nHealthcare Leaders,\\nNVIDIA CEO Share AI\\nInnovation Across the\\nIndustry\\n\\nBy applying multiple lightweight, specialized models as guardrails, developers can cover gaps that\\nmay occur when only more general global policies and protections exist — as a one-size-fits-all\\napproach doesn’t properly secure and control complex agentic AI workflows.\\nSmall language models, like those in the NeMo Guardrails collection, offer lower latency and are\\ndesigned to run efficiently, even in resource-constrained or distributed environments. This makes\\nthem ideal for scaling AI applications in industries such as healthcare, automotive and\\nmanufacturing, in locations like hospitals or warehouses.\\n\\nIndustry Leaders and Partners Safeguard AI With NeMo Guardrails\\nNeMo Guardrails, available to the open-source community, helps developers orchestrate multiple AI\\nsoftware policies — called rails — to enhance LLM application security and control. It works with\\nNVIDIA NIM microservices to offer a robust framework for building AI systems that can be\\ndeployed at scale without compromising on safety or performance.\\nAmdocs, a leading global provider of software and services to communications and media\\ncompanies, is harnessing NeMo Guardrails to enhance AI-driven customer interactions by\\ndelivering safer, more accurate and contextually appropriate responses.\\n“Technologies like NeMo Guardrails are essential for safeguarding generative AI applications,\\nhelping make sure they operate securely and ethically,” said Anthony Goonetilleke, group president\\nof technology and head of strategy at Amdocs. “By integrating NVIDIA NeMo Guardrails into our\\namAIz platform, we are enhancing the platform’s ‘Trusted AI’ capabilities to deliver agentic\\nexperiences that are safe, reliable and scalable. This empowers service providers to deploy AI\\nsolutions safely and with confidence, setting new standards for AI innovation and operational\\nexcellence.”\\nCerence AI, a company specializing in AI solutions for the automotive industry, is using NVIDIA\\nNeMo Guardrails to help ensure its in-car assistants deliver contextually appropriate, safe\\ninteractions powered by its CaLLM family of large and small language models.\\n“Cerence AI relies on high-performing, secure solutions from NVIDIA to power our in-car assistant\\ntechnologies,” said Nils Schanz, executive vice president of product and technology at Cerence AI.\\n“Using NeMo Guardrails helps us deliver trusted, context-aware solutions to our automaker\\ncustomers and provide sensible, mindful and hallucination-free responses. In addition, NeMo\\nGuardrails is customizable for our automaker customers and helps us filter harmful or unpleasant\\nrequests, securing our CaLLM family of language models from unintended or inappropriate\\ncontent delivery to end users.”\\nLowe’s, a leading home improvement retailer, is leveraging generative AI to build on the deep\\nexpertise of its store associates. By providing enhanced access to comprehensive product\\nknowledge, these tools empower associates to answer customer questions, helping them find the\\nright products to complete their projects and setting a new standard for retail innovation and\\ncustomer satisfaction.\\n“We’re always looking for ways to help associates to above and beyond for our customers,” said\\nChandhu Nair, senior vice president of data, AI and innovation at Lowe’s. “With our recent\\ndeployments of NVIDIA NeMo Guardrails, we ensure AI-generated responses are safe, secure and\\nreliable, enforcing conversational boundaries to deliver only relevant and appropriate content.”\\nTo further accelerate AI safeguards adoption in AI application development and deployment in\\nretail, NVIDIA recently announced at the NRF show that its NVIDIA AI Blueprint for retail shopping\\nassistants incorporates NeMo Guardrails microservices for creating more reliable and controlled\\ncustomer interactions during digital shopping experiences.\\nConsulting leaders Taskus, Tech Mahindra and Wipro are also integrating NeMo Guardrails into\\ntheir solutions to provide their enterprise clients safer, more reliable and controlled generative AI\\napplications.\\nNeMo Guardrails is open and extensible, offering integration with a robust ecosystem of leading AI\\nsafety model and guardrail providers, as well as AI observability and development tools. It supports\\nintegration with ActiveFence’s ActiveScore, which filters harmful or inappropriate content in\\nconversational AI applications, and provides visibility, analytics and monitoring.\\nHive, which provides its AI-generated content detection models for images, video and audio\\ncontent as NIM microservices, can be easily integrated and orchestrated in AI applications using\\nNeMo Guardrails.\\nThe Fiddler AI Observability platform easily integrates with NeMo Guardrails to enhance AI guardrail\\nmonitoring capabilities. And Weights & Biases, an end-to-end AI developer platform, is expanding\\nthe capabilities of W&B Weave by adding integrations with NeMo Guardrails microservices. This\\nenhancement builds on Weights & Biases’ existing portfolio of NIM integrations for optimized AI\\ninferencing in production.\\n\\nNeMo Guardrails Offers Open-Source Tools for AI Safety Testing\\nDevelopers ready to test the effectiveness of applying safeguard models and other rails can use\\nNVIDIA Garak — an open-source toolkit for LLM and application vulnerability scanning developed\\nby the NVIDIA Research team.\\nWith Garak, developers can identify vulnerabilities in systems using LLMs by assessing them for\\nissues such as data leaks, prompt injections, code hallucination and jailbreak scenarios. By\\ngenerating test cases involving inappropriate or incorrect outputs, Garak helps developers detect\\nand address potential weaknesses in AI models to enhance their robustness and safety.\\n\\nAvailability\\nNVIDIA NeMo Guardrails microservices, as well as NeMo Guardrails for rail orchestration and the\\nNVIDIA Garak toolkit, are now available for developers and enterprises. Developers can get started\\nbuilding AI safeguards into AI agents for customer service using NeMo Guardrails with this tutorial.\\nSee notice regarding software product information.\\n\\nCategories: Generative AI\\nTags: Artificial Intelligence | Cybersecurity | NVIDIA Blueprints | NVIDIA NeMo | NVIDIA NIM\\n1\\nLogin\\n\\ue603\\n\\n0 Comments\\n\\nG\\n\\nStart the discussion…\\n\\nLOG IN WITH\\n\\nOR SIGN UP WITH DISQUS\\n\\n?\\n\\nName\\n\\n\\uf109\\n\\nShare\\n\\nBest\\n\\nNewest\\n\\nOldest\\n\\nBe the first to comment.\\n\\nSubscribe\\n\\nPrivacy\\n\\nDo Not Sell My Data\\n\\nUnveiling a New Era of Local AI With NVIDIA NIM Microservices and AI\\nBlueprints\\nNew NIM microservices and AI Blueprints unlock generative AI on RTX AI PCs and workstation — plus, more announcements\\nfrom CES recapped in this first installment of the RTX AI Garage series.\\nJanuary 8, 2025 by Jesse Clayton\\n\\nu\\n\\nShare\\n\\nf\\nh\\nd\\n\\nReading Time: 5 mins\\n\\nOver the past year, generative AI has transformed the way people live, work and play, enhancing\\neverything from writing and content creation to gaming, learning and productivity. PC enthusiasts\\nand developers are leading the charge in pushing the boundaries of this groundbreaking\\ntechnology.\\nCountless times, industry-defining technological breakthroughs have been invented in one place —\\na garage. This week marks the start of the RTX AI Garage series, which will offer routine content for\\ndevelopers and enthusiasts looking to learn more about NVIDIA NIM microservices and AI\\nBlueprints, and how to build AI agents, creative workflow, digital human, productivity apps and\\nmore on AI PCs. Welcome to the RTX AI Garage.\\nThis first installment spotlights announcements made earlier this week at CES, including new AI\\nfoundation models available on NVIDIA RTX AI PCs that take digital humans, content creation,\\nproductivity and development to the next level.\\n\\nAll NVIDIA News\\n\\nThese models — offered as NVIDIA NIM microservices — are powered by new GeForce RTX 50\\nSeries GPUs. Built on the NVIDIA Blackwell architecture, RTX 50 Series GPUs deliver up to 3,352\\ntrillion AI operations per second of performance, 32GB of VRAM and feature FP4 compute,\\ndoubling AI inference performance and enabling generative AI to run locally with a smaller memory\\nfootprint.\\n\\nHow This NVIDIA Kaggle\\nGrandmaster Merges\\nInnovation and Play\\n\\nNVIDIA also introduced NVIDIA AI Blueprints — ready-to-use, preconfigured workflows, built on NIM\\nmicroservices, for applications like digital humans and content creation.\\n\\nNVIDIA Releases NIM\\nMicroservices to\\nSafeguard Applications\\nfor Agentic AI\\n\\nNIM microservices and AI Blueprints empower enthusiasts and developers to build, iterate and\\ndeliver AI-powered experiences to the PC faster than ever. The result is a new wave of compelling,\\npractical capabilities for PC users.\\n\\nFantastic Four-ce\\nAwakens: Season One of\\n‘Marvel Rivals’ Joins\\nGeForce NOW\\n\\nFast-Track AI With NVIDIA NIM\\nThere are two key challenges to bringing AI advancements to PCs. First, the pace of AI research is\\nbreakneck, with new models appearing daily on platforms like Hugging Face, which now hosts over\\na million models. As a result, breakthroughs quickly become outdated.\\n\\nHow AI Is Enhancing\\nSurgical Safety and\\nEducation\\n\\nSecond, adapting these models for PC use is a complex, resource-intensive process. Optimizing\\nthem for PC hardware, integrating them with AI software and connecting them to applications\\nrequires significant engineering effort.\\nNVIDIA NIM helps address these challenges by offering prepackaged, state-of-the-art AI models\\noptimized for PCs. These NIM microservices span model domains, can be installed with a single\\nclick, feature application programming interfaces (APIs) for easy integration, and harness NVIDIA AI\\nsoftware and RTX GPUs for accelerated performance.\\n\\nNVIDIA GTC 2025:\\nQuantum Day to\\nIlluminate the Future of\\nQuantum Computing\\n\\nAt CES, NVIDIA announced a pipeline of NIM microservices for RTX AI PCs, supporting use cases\\nspanning large language models (LLMs), vision-language models, image generation, speech,\\nretrieval-augmented generation (RAG), PDF extraction and computer vision.\\nThe new Llama Nemotron family of open models provide high accuracy on a wide range of agentic\\ntasks. The Llama Nemotron Nano model, which will be offered as a NIM microservice for RTX AI PCs\\nand workstations, excels at agentic AI tasks like instruction following, function calling, chat, coding\\nand math.\\nSoon, developers will be able to quickly download and run these microservices on Windows 11 PCs\\nusing Windows Subsystem for Linux (WSL).\\n\\nIntroducing Project R2X | A Preview of a RTX-Powered Digital Human Interface\\n\\nTo demonstrate how enthusiasts and developers can use NIM to build AI agents and assistants,\\nNVIDIA previewed Project R2X, a vision-enabled PC avatar that can put information at a user’s\\nfingertips, assist with desktop apps and video conference calls, read and summarize documents,\\nand more. Sign up for Project R2X updates.\\nBy using NIM microservices, AI enthusiasts can skip the complexities of model curation,\\noptimization and backend integration and focus on creating and innovating with cutting-edge AI\\nmodels.\\n\\nWhat’s in an API?\\nAn API is the way in which an application communicates with a software library. An API defines a\\nset of “calls” that the application can make to the library and what the application can expect in\\nreturn. Traditional AI APIs require a lot of setup and configuration, making AI capabilities harder to\\nuse and hampering innovation.\\nNIM microservices expose easy-to-use, intuitive APIs that an application can simply send requests\\nto and get a response. In addition, they’re designed around the input and output media for\\ndifferent model types. For example, LLMs take text as input and produce text as output, image\\ngenerators convert text to image, speech recognizers turn speech to text and so on.\\nThe microservices are designed to integrate seamlessly with leading AI development and agent\\nframeworks such as AI Toolkit for VSCode, AnythingLLM, ComfyUI, Flowise AI, LangChain, Langflow\\nand LM Studio. Developers can easily download and deploy them from build.nvidia.com.\\nBy bringing these APIs to RTX, NVIDIA NIM will accelerate AI innovation on PCs.\\nEnthusiasts are expected to be able to experience a range of NIM microservices using an\\nupcoming release of the NVIDIA ChatRTX tech demo.\\n\\nA Blueprint for Innovation\\nBy using state-of-the-art models, prepackaged and optimized for PCs, developers and enthusiasts\\ncan quickly create AI-powered projects. Taking things a step further, they can combine multiple AI\\nmodels and other functionality to build complex applications like digital humans, podcast\\ngenerators and application assistants.\\nNVIDIA AI Blueprints, built on NIM microservices, are reference implementations for complex AI\\nworkflows. They help developers connect several components, including libraries, software\\ndevelopment kits and AI models, together in a single application.\\n\\nNVIDIA NIM Microservices for RTX AI PCs\\n\\nAI Blueprints include everything that a developer needs to build, run, customize and extend the\\nreference workflow, which includes the reference application and source code, sample data, and\\ndocumentation for customization and orchestration of the different components.\\nAt CES, NVIDIA announced two AI Blueprints for RTX: one for PDF to podcast, which lets users\\ngenerate a podcast from any PDF, and another for 3D-guided generative AI, which is based on\\nFLUX.1 [dev] and expected be offered as a NIM microservice, offers artists greater control over\\ntext-based image generation.\\nWith AI Blueprints, developers can quickly go from AI experimentation to AI development for\\ncutting-edge workflows on RTX PCs and workstations.\\n\\nBuilt for Generative AI\\nThe new GeForce RTX 50 Series GPUs are purpose-built to tackle complex generative AI challenges,\\nfeaturing fifth-generation Tensor Cores with FP4 support, faster G7 memory and an AImanagement processor for efficient multitasking between AI and creative workflows.\\nThe GeForce RTX 50 Series adds FP4 support to help bring better performance and more models\\nto PCs. FP4 is a lower quantization method, similar to file compression, that decreases model sizes.\\nCompared with FP16 — the default method that most models feature — FP4 uses less than half of\\nthe memory, and 50 Series GPUs provide over 2x performance compared with the previous\\ngeneration. This can be done with virtually no loss in quality with advanced quantization methods\\noffered by NVIDIA TensorRT Model Optimizer.\\nFor example, Black Forest Labs’ FLUX.1 [dev] model at FP16 requires over 23GB of VRAM, meaning\\nit can only be supported by the GeForce RTX 4090 and professional GPUs. With FP4, FLUX.1 [dev]\\nrequires less than 10GB, so it can run locally on more GeForce RTX GPUs.\\nWith a GeForce RTX 4090 with FP16, the FLUX.1 [dev] model can generate images in 15 seconds\\nwith 30 steps. With a GeForce RTX 5090 with FP4, images can be generated in just over five\\nseconds.\\n\\nGet Started With the New AI APIs for PCs\\nNVIDIA NIM microservices and AI Blueprints are expected to be available starting next month, with\\ninitial hardware support for GeForce RTX 50 Series, GeForce RTX 4090 and 4080, and NVIDIA RTX\\n6000 and 5000 professional GPUs. Additional GPUs will be supported in the future.\\nNIM-ready RTX AI PCs are expected to be available from Acer, ASUS, Dell, GIGABYTE, HP, Lenovo,\\nMSI, Razer and Samsung, and from local system builders Corsair, Falcon Northwest, LDLC,\\nMaingear, Mifcon, Origin PC, PCS and Scan.\\nGeForce RTX 50 Series GPUs and laptops deliver game-changing performance, power\\ntransformative AI experiences, and enable creators to complete workflows in record time. Rewatch\\nNVIDIA CEO Jensen Huang’s keynote to learn more about NVIDIA’s AI news unveiled at CES.\\nSee notice regarding software product information.\\n\\nCategories: Generative AI\\nTags: AI Decoded | Artificial Intelligence | GeForce | NVIDIA RTX\\nLoad Comments\\n\\nCorporate Information\\n\\nGet Involved\\n\\nNews & Events\\n\\nAbout NVIDIA\\n\\nForums\\n\\nNewsroom\\n\\nCorporate Overview\\n\\nCareers\\n\\nNVIDIA Blog\\n\\nTechnologies\\n\\nDeveloper Home\\n\\nNVIDIA Technical Blog\\n\\nNVIDIA Research\\n\\nJoin the Developer Program\\n\\nWebinars\\n\\nInvestors\\n\\nNVIDIA Partner Network\\n\\nStay Informed\\n\\nSocial Responsibility\\n\\nNVIDIA Inception\\n\\nEvents Calendar\\n\\nNVIDIA Foundation\\n\\nResources for Venture Capitalists\\n\\nNVIDIA GTC\\n\\nVenture Capital (NVentures)\\n\\nNVIDIA On-Demand\\n\\nTechnical Training\\nTraining for IT Professionals\\nProfessional Services for Data Science\\n\\nEXPLORE OUR REGIONAL BLOGS AND OTHER SOCIAL NETWORKS\\n\\ne\\nUSA - United States\\n\\nPrivacy Policy\\n\\nManage My Privacy\\n\\nContact\\nCopyright © 2025 NVIDIA Corporation\\n\\nLegal\\n\\nAccessibility\\n\\nProduct Security\\n\\n\\x0c'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'C:\\\\Users\\\\Subham Gupta\\\\Desktop\\\\Work\\\\Research ChatBot\\\\blogs_nvidia_com__blog_nemo-guardrails-nim-microservices_.txt'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata # Nmae of your txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the text from any page -- use Unstructured url _loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Using cached unstructured-0.16.13-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting libmagic\n",
      "  Using cached libmagic-1.0.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting python-magic-bin\n",
      "  Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
      "Requirement already satisfied: chardet in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (5.2.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (1.26.4)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (4.11.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.29.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ndjson (from unstructured)\n",
      "  Downloading ndjson-0.3.1-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from nltk->unstructured) (2024.9.11)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests->unstructured) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from requests->unstructured) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (43.0.0)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pydantic<2.11.0,>=2.10.3 (from unstructured-client->unstructured)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from pydantic<2.11.0,>=2.10.3->unstructured-client->unstructured) (0.6.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<2.11.0,>=2.10.3->unstructured-client->unstructured)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\subham gupta\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\n",
      "Downloading unstructured-0.16.13-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
      "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.29.0-py3-none-any.whl (63 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Building wheels for collected packages: libmagic\n",
      "  Building wheel for libmagic (setup.py): started\n",
      "  Building wheel for libmagic (setup.py): finished with status 'done'\n",
      "  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4279 sha256=568ea31673f17991afed4df9df5c67fff76f9b2ac962074ff139bc52c3ffd4e2\n",
      "  Stored in directory: c:\\users\\subham gupta\\appdata\\local\\pip\\cache\\wheels\\ba\\32\\b5\\da21074580720b7a55fbf1a7597e3b1a325d12940ea6bd661b\n",
      "Successfully built libmagic\n",
      "Installing collected packages: python-magic-bin, ndjson, libmagic, filetype, typing-extensions, rapidfuzz, python-magic, python-iso639, pypdf, olefile, langdetect, jsonpath-python, html5lib, eval-type-backport, emoji, backoff, aiofiles, python-oxmsg, pydantic-core, pydantic, unstructured-client, unstructured\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed aiofiles-24.1.0 backoff-2.2.1 emoji-2.14.1 eval-type-backport-0.2.2 filetype-1.2.0 html5lib-1.1 jsonpath-python-1.0.6 langdetect-1.0.9 libmagic-1.0 ndjson-0.3.1 olefile-0.47 pydantic-2.10.5 pydantic-core-2.27.2 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-magic-bin-0.4.14 python-oxmsg-0.0.1 rapidfuzz-3.11.0 typing-extensions-4.12.2 unstructured-0.16.13 unstructured-client-0.29.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Subham Gupta\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls = [\"https://medium.com/photomath/10-reasons-to-love-math-678e5453cf3d\",\n",
    "                                       \"https://www.investopedia.com/who-is-alexander-hamilton-5205028\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the text say if chunks are smaller and could be made closer to the max size of 4096 as the extra tokens don't go to waste and also take overlapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceTransformers and FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectors = encoder.encode(df.text)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = vectors.shape[-1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# L2  --> Euclidean distance\n",
    "\n",
    "# This is an empty index of size = 768\n",
    "index = faiss.IndexFlatL2(dim) # here dim = size of each vector (Number of Dimensions)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"I want to but a polo t-shirt\"\n",
    "vec = encoder.encode(search_query)\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "search_vector = np.array(vec).reshape(-1,1)\n",
    "search_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, I = index.search(search_vector, k = 2) # Here k gives us the Number of similar vectors from our DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = \"your_openai_api_key\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env (especially openai api key)\n",
    "\n",
    "st.title(\"RockyBot: News Research Tool 📈\")\n",
    "st.sidebar.title(\"News Article URLs\")\n",
    "\n",
    "urls = []\n",
    "for i in range(3):\n",
    "    url = st.sidebar.text_input(f\"URL {i+1}\")\n",
    "    urls.append(url)\n",
    "\n",
    "process_url_clicked = st.sidebar.button(\"Process URLs\")\n",
    "file_path = \"faiss_store_openai.pkl\"\n",
    "\n",
    "main_placeholder = st.empty()\n",
    "llm = OpenAI(temperature=0.9, max_tokens=500)\n",
    "\n",
    "if process_url_clicked:\n",
    "    # load data\n",
    "    loader = UnstructuredURLLoader(urls=urls)\n",
    "    main_placeholder.text(\"Data Loading...Started...✅✅✅\")\n",
    "    data = loader.load()\n",
    "    # split data\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=['\\n\\n', '\\n', '.', ','],\n",
    "        chunk_size=1000\n",
    "    )\n",
    "    main_placeholder.text(\"Text Splitter...Started...✅✅✅\")\n",
    "    docs = text_splitter.split_documents(data)\n",
    "    # create embeddings and save it to FAISS index\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore_openai = FAISS.from_documents(docs, embeddings)\n",
    "    main_placeholder.text(\"Embedding Vector Started Building...✅✅✅\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Save the FAISS index to a pickle file\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(vectorstore_openai, f)\n",
    "\n",
    "query = main_placeholder.text_input(\"Question: \")\n",
    "if query:\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            vectorstore = pickle.load(f)\n",
    "            chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
    "            result = chain({\"question\": query}, return_only_outputs=True)\n",
    "            # result will be a dictionary of this format --> {\"answer\": \"\", \"sources\": [] }\n",
    "            st.header(\"Answer\")\n",
    "            st.write(result[\"answer\"])\n",
    "\n",
    "            # Display sources, if available\n",
    "            sources = result.get(\"sources\", \"\")\n",
    "            if sources:\n",
    "                st.subheader(\"Sources:\")\n",
    "                sources_list = sources.split(\"\\n\")  # Split the sources by newline\n",
    "                for source in sources_list:\n",
    "                    st.write(source)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How faiss works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
